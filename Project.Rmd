---
title: "DSCI 512 Final Project"
author: "Lauren Schmiedeler"
date: "2022-12-11"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

</br>

### 1. Data Preparation 

</br>
**1. Open an rmd and load the `insurance.csv` dataset.**
```{r, warning = F, message = F}
library(tidyverse)

# read in insurance.csv
insurance <- read.csv("insurance.csv")
# convert sex, smoker, and region to factors
insurance <- mutate(insurance, sex = factor(sex), smoker = factor(smoker), region = factor(region))

head(insurance)
```

</br>
**2. In the data frame, log transform the variable `charges` and name it `log_charges`.**
```{r}
insurance$log_charges <- log(insurance$charges)
head(insurance)
```

</br>
**3. Use the `sample ()` function with `set.seed` equal to 1 to generate row indexes for your training and tests sets, with 70% of the row indexes for your training set and 30% for your test set. Do not use any method other than the `sample()` function for splitting your data.**
```{r}
set.seed(1)
train_i <- sample(1:nrow(insurance), as.integer(0.7 * nrow(insurance)))
train <- insurance[train_i,]
test <- insurance[-train_i,]
```

</br>

### 2. Build a Multiple Regression Model

</br>
**1. Perform multiple linear regression with `log_charges` as the response and the predictors are `age`, `sex`, `bmi`, `children`, `smoker`, and `region`. Print out the results using the `summary()` function. Use the training dataset you created in 1 above.** 
```{r}
mod_lm <- lm(log_charges ~ age + sex + bmi + children + smoker + region, data = train)
summary_mod_lm <- summary(mod_lm)
summary_mod_lm
```

</br>
**2. Is there a relationship between the predictors and the response?**  Yes, there is a relationship between the predictors and the response.  The $R^2$ value for this model indicates that almost 80% of the variation in `log_charges` is explained by the predictors.
```{r}
summary_mod_lm$r.squared
```

</br>
**3. Does `sex` have a statistically significant relationship to the response?**  Yes, based on the p-value associated with the coefficient for `sexmale` (which is about 0.041), we reject the null hypothesis that there is no relationship between `log_charges` and `sex` at a 5% significance level.
```{r}
summary_mod_lm$coefficients
```

</br>
**4. Compute the test error of the model in 2a. Report the RMSE.**
```{r}
# create a function that calculates the RMSE
rmse <- function(observed, predicted) {
  sqrt(mean((observed - predicted)**2))
}

predict_mod_lm <- predict(mod_lm, newdata = test)
rmse_mod_lm <- rmse(test$log_charges, predict_mod_lm)
rmse_mod_lm
```

</br>

### 3. Build a Regression Tree Model

</br>
**1. Build a regression tree model using function `tree()`, where `log_charges` is the response and the predictors are `age`, `sex`, `bmi`, `children`, `smoker`, and `region`.**
```{r, warning = F, message = F}
library(tree)

mod_tree <- tree(log_charges ~ age + sex + bmi + children + smoker + region, data = train)
summary(mod_tree)
```

</br>
**2. Find the optimal tree and display the results in a graphic. Report the best size.**  The best size is 3.
```{r}
mod_tree_cv <- cv.tree(mod_tree)
plot(mod_tree_cv$size, mod_tree_cv$dev)
```

</br>
**3. Justify the number you picked for the optimal tree with regard to the principle of the variance-bias trade-off.**  With a more complex model (a tree with a larger size), the variance will increase.  With a less complex model (a tree with a smaller size), the bias (or accuracy) will increase.

</br>
**4. Prune the tree using the optimal size found in 3b.**
```{r}
mod_tree_prune <- prune.tree(mod_tree, best = 3)
```

</br>
**5. Plot the best tree model and give labels.**
```{r}
plot(mod_tree_prune)
text(mod_tree_prune)
```

</br>
**6. Calculate the RMSE for the best model.**
```{r}
predict_mod_tree <- predict(mod_tree_prune, newdata = test)
rmse_mod_tree <- rmse(test$log_charges, predict_mod_tree)
rmse_mod_tree
```

</br>

### 4. Build a Random Forest Model

</br>
**1. Build a random forest model using function `randomForest()`, where `log_charges` is the response and the predictors are `age`, `sex`, `bmi`, `children`, `smoker`, and `region`.**
```{r, warning = F, message = F}
library(randomForest)

mod_rand_forest <- randomForest(log_charges ~ age + sex + bmi + children + smoker + region, data = train)
mod_rand_forest
```

</br>
**2. Compute the test error (using the test data set).**
```{r}
predict_mod_rand_forest <- predict(mod_rand_forest, newdata = test)
rmse_mod_rand_forest <- rmse(test$log_charges, predict_mod_rand_forest)
rmse_mod_rand_forest
```

</br>
**3. Extract variable importance measure using the `importance()` function.**
```{r}
importance(mod_rand_forest)
```

</br>
**4. Plot the variable importance using the function, `varImpPlot()`. Which are the top 3 important predictors in this model?** The top 3 important predictors in this model are `smoker`, `age`, and `bmi`.
```{r}
varImpPlot(mod_rand_forest)
```

</br>

### 5. Build a Support Vector Machine Model

</br>
**1. The response is `charges` and the predictors are `age`, `sex`, `bmi`, `children`, `smoker`, and `region`. Please use the `svm()` function with radial `kernel` and `gamma` = 5 and `cost` = 50.**
```{r, warning = F, message = F}
library(e1071)

mod_svm <- svm(charges ~ age + sex + bmi + children + smoker + region, data = train, kernel = "radial", gamma = 5, cost = 50)
summary(mod_svm)
```

</br>
**2. Perform a grid search to find the best model with potential `cost`: 1, 10, 50, 100 and potential `gamma`: 1,3 and 5 and potential `kernel`: "linear", "radial" and "sigmoid".**
```{r}
mod_svm_tune <- tune(svm, charges ~ age + sex + bmi + children + smoker + region, data = train, ranges = list(kernel = c("linear", "radial", "sigmoid"), gamma = c(1, 3, 5), cost = c(1, 10, 50, 100)))
```

</br>
**3. Print out the model results. What are the best model parameters?**  The best model parameters are `kernel` = radial, `gamma` = 1, and `cost` = 1.
```{r}
mod_svm_tune$best.parameters
```

</br>
**4. Forecast `charges` using the test dataset and the best model found in 3.**
```{r}
predict_mod_svm <- predict(mod_svm_tune$best.model, newdata = test)
```

</br>
**5. Compute the RMSE (Root Mean Squared Error) on the test data.**
```{r}
rmse(test$charges, predict_mod_svm)
```

</br>

### 6. Perform k-means Cluster Analysis

</br>
**1. Remove the `sex`, `smoker`, and `region`, since they are not numerical values.**
```{r}
# remove sex, smoker, and region (non-numeric features)
insurance_numeric <- select(insurance, -sex, -smoker, -region, -log_charges)
# scale the remaining features and convert to a data frame
insurance_numeric_scaled_mod_kmeans <- as.data.frame(scale(insurance_numeric))

head(insurance_numeric_scaled_mod_kmeans)
```

</br>
**2. Determine the optimal number of clusters. Justify your answer.**  The optimal number of clusters is 4.  Before k = 4, the cost decreases significantly between each value of k.  After k = 4, the cost is almost flat between each value of k.
```{r, warning = F, message = F}
library(factoextra)

fviz_nbclust(insurance_numeric_scaled_mod_kmeans, kmeans, method = "wss")
```

</br>
**3. Perform k-means clustering using the optimal number of clusters from 5b.**
```{r}
mod_kmeans <- kmeans(insurance_numeric_scaled_mod_kmeans, centers = 4, nstart = 25)
```

</br>
**4. Visualize the clusters in different colors.**
```{r}
fviz_cluster(mod_kmeans, data = insurance_numeric_scaled_mod_kmeans, labelsize = 0)
```

</br>

### 7. Build a Neural Network Model

</br>
**1. Remove the `sex`, `smoker`, and `region`, since they are not numerical values.**
```{r}
head(insurance_numeric)
```

</br>
**2. Standardize the inputs using the `scale()` function.**
```{r}
insurance_numeric_scaled_mod_nn <- cbind(as.data.frame(scale(select(insurance_numeric, -charges))), insurance_numeric$charges)
names(insurance_numeric_scaled_mod_nn) <- c(names(insurance_numeric_scaled_mod_nn)[1:(ncol(insurance_numeric_scaled_mod_nn) - 1)], "charges")
head(insurance_numeric_scaled_mod_nn)
```

</br>
**3. Convert the standardized inputs to a data frame using the `as.data.frame()` function.**
```{r}
head(insurance_numeric_scaled_mod_nn)
```

</br>
**4. Split the dataset into a training set containing 80% of the original data and the test set containing the remaining 20%.**
```{r}
train_i <- sample(1:nrow(insurance_numeric_scaled_mod_nn), as.integer(0.8 * nrow(insurance_numeric_scaled_mod_nn)))
train <- insurance_numeric_scaled_mod_nn[train_i,]
test <- insurance_numeric_scaled_mod_nn[-train_i,]
```

</br>
**5. The response is `charges` and the predictors are `age`, `bmi`, and `children`. Please use 1 hidden layer with 1 neuron.**
```{r, warning = F, message = F}
library(neuralnet)

mod_nn <- neuralnet(charges ~ age + bmi + children, data = train, hidden = c(1))
```

</br>
**6. Plot the neural networks.**
```{r}
plot(mod_nn)
```

</br>
**7. Forecast the `charges` in the test dataset.**
```{r}
predict_mod_nn <- predict(mod_nn, newdata = test)
```

</br>
**8. Get the observed `charges` of the test dataset.**
```{r}
observed <- test$charges
```

</br>
**9. Compute test error (RMSE).**
```{r}
rmse_mod_nn <- rmse(observed, predict_mod_nn)
rmse_mod_nn
```

</br>

### Putting it all Together

</br>
**1. a. For predicting insurance charges, your supervisor asks you to choose the best model among the multiple regression, regression tree, and random forest. Compare the test RMSEs of the models generated above. Display the names for these models (Multiple Linear Regression, Regression Tree, and Random Forest) and their corresponding test RMSEs in a `data.frame`. Label the column in your data frame with the labels as `Model.Type`, and label the column with the test RMSEs as `Test.RMSE` and round the data in this column to 4 decimal places. Present the formatted data to your supervisor and recommend which model is best and why. b. Another supervisor from the sales department has requested your help to create a predictive model that his sales representatives can use to explain to clients what the potential costs could be for different kinds of customers, and they need an easy and visual way of explaining it. What model would you recommend, and what are the benefits and disadvantages of your recommended model compared to other models?**  The random forest model is the best according to RMSE because its test RMSE is better than that of both the multiple linear regression model and the regression tree model.  However, for part (b), I would recommend the multiple linear regression model because it is easy to explain using its coefficients, which are obtained using `summary(mod_lm)`.  The disadvantage of this simpler model compared to the random forest model is that it has a higher test RMSE.  Note that the regression tree model is also easy to explain, but its test RMSE is higher than that of the multiple linear regression model.
```{r}
data.frame(Model.Type = c("Multiple Linear Regression", "Regression Tree", "Random Forest"), Test.RMSE = round(c(rmse_mod_lm, rmse_mod_tree, rmse_mod_rand_forest), 4))
```

</br>
**2. The supervisor from the sales department likes your regression tree model. But she says that the salespeople say the numbers in it are way too low and suggests that maybe the numbers on the leaf nodes predicting charges are log transformations of the actual charges. You realize that in step 1b of this project that you had indeed transformed charges using the log function. And now you realize that you need to reverse the transformation in your final output. The solution you have is to reverse the log transformation of the variables in the regression tree model you created and redisplay the result.**
```{r}
# Copy your pruned tree model to a new variable name.
pruned_tree <- mod_tree_prune

# In your new variable, find the data.frame named “frame” and reverse the log transformation on the data.frame column yval using the exp() function.
pruned_tree$frame$yval <- exp(pruned_tree$frame$yval)

# After you reverse the log transform on the yval column, then replot the tree with labels.
plot(pruned_tree)
text(pruned_tree)
```

